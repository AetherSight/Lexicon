# Ollama Configuration
# Set the Ollama server URL (default: http://localhost:11434)
OLLAMA_HOST=http://localhost:11434

# Ollama Model Name (default: qwen3-vl:8b-thinking)
OLLAMA_MODEL=qwen3-vl:8b-thinking

# API Key (not required for Ollama, but kept for compatibility with other API providers)
API_KEY=

# Equipment Data CSV Path (required)
# Can be absolute path or relative to project root
# Example: csv/equipment_labels_epoch_1.csv
CSV_PATH=csv/equipment_labels_epoch_1.csv

# Server Configuration (optional)
HOST=0.0.0.0
PORT=9000

# Retry Configuration (optional)
# Maximum number of retries when JSON parsing fails (default: 3)
MAX_RETRIES=3

# Debug Mode (optional)
# Set to 'true' to enable debug logging for retry attempts
DEBUG=false
